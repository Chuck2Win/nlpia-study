{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP in action-chapter2.ipynb","provenance":[],"collapsed_sections":["Vz7NscA7Bv94","0ThG1grqJZ-s","sU5CeejGIoQ5","Q6k_P-oURofn","pcYHgQeZOZTx","NhrmxhHzbNuS","wH86GcOfWEuc","dn2YX1fAlmHl"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"SX6CxAAPG4b6"},"source":["# 챗봇팀 깃 저장소.\n","\n","https://github.com/ai-lab-kr-7-chatbot-team\n","\n","# 책 깃헙\n","https://github.com/totalgood/nlpia\n","# 챕터2 소스 ( ? )\n","https://github.com/totalgood/nlpia/blob/master/src/nlpia/book/examples/ch02.md\n","\n","# NLP token 관련 용어\n","* 자소, 문자소 (grapheme)\n","> text를 구성하는 가장 작은 단위\n","\n","* 형태소(morpheme)\n","> 일정한 의미가 있는 가장 작은 말(word)의 단위\n","\n","* n-gram\n","> 숙어. 단어의 쌍(word의 pair) , 2-gram(bigram) , 3-gram(trigram)\n","\n","* 어간추출(stemming)\n","> 한단어의 여러변형을 동일한 군(group) 으로 묶는 것.\n","\n","* 말뭉치(corpus)\n","```\n","NLP의 특정한 목적을 위해 언어의 표본을 추출한 집합\t\n","자연언어를 대개 형태소 분석하여 추출.\t\n","확률/통계적 기법과 시계열적인 접근으로 전체를 파악.\n","인문학에 자연과학적 방법론이 가장 성공적으로 적용된 경우\n","```\n","\n","* 우리말 말뭉치 \n","\n","0. KoNLPy(말뭉치 링크 모음)\n","1. 세종 말뭉치 자동 다운로드\n","2. 카이스트 말뭉치\n","3. Hantec 2.0\n","4. 한국일보(HKIB)\n","5. 연세말뭉치\n","6. ETRI\n","7. 세종\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"iDLFU_RUh5p3"},"source":["\"\"\" NLPIA Chapter 2 Section 2.1 Code Listings and Snippets \"\"\"\n","import pandas as pd\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LflGc1EOhHQa","executionInfo":{"status":"ok","timestamp":1601211162510,"user_tz":-540,"elapsed":2035,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"1a87c7ea-cc5d-45f7-edd4-2d6875f3361d","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["sentence = \"Thomas Jefferson began building Monticello at the age of twenty-six.\"\n","sentence.split()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Thomas',\n"," 'Jefferson',\n"," 'began',\n"," 'building',\n"," 'Monticello',\n"," 'at',\n"," 'the',\n"," 'age',\n"," 'of',\n"," 'twenty-six.']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"CxSFX9Nv0OSS"},"source":["# 단어 수치 백터 ( word numerical vector )"]},{"cell_type":"code","metadata":{"id":"ReSjp--zhzAi","executionInfo":{"status":"ok","timestamp":1601211162511,"user_tz":-540,"elapsed":2027,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"9ed64950-cb87-4ea3-bef1-57190208cc2d","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# As you can see, this simple Python function already does a decent job tokenizing the example sentence.\n","# A couple more vanilla python statements and you can create numerical vector representations for each word.\n","sorted(dict([(token, 1) for token in sentence.split()]).items())\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Jefferson', 1),\n"," ('Monticello', 1),\n"," ('Thomas', 1),\n"," ('age', 1),\n"," ('at', 1),\n"," ('began', 1),\n"," ('building', 1),\n"," ('of', 1),\n"," ('the', 1),\n"," ('twenty-six.', 1)]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"TXmmAXfgiESo","executionInfo":{"status":"ok","timestamp":1601211162512,"user_tz":-540,"elapsed":2019,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"7b7cf16e-fdb5-468a-b9b8-84b508af5032","colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["# vector :  (x,y,z) = ( 2.3 , 3, 2)\n","sentence = \"Thomas Jefferson began building Monticello at the age of 26.\" #sent0  \n","series1 = pd.Series(dict([(token, 1) for token in sentence.split()]))\n","df = pd.DataFrame(series1, columns=['sent']).T\n","df\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Thomas</th>\n","      <th>Jefferson</th>\n","      <th>began</th>\n","      <th>building</th>\n","      <th>Monticello</th>\n","      <th>at</th>\n","      <th>the</th>\n","      <th>age</th>\n","      <th>of</th>\n","      <th>26.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>sent</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Thomas  Jefferson  began  building  Monticello  at  the  age  of  26.\n","sent       1          1      1         1           1   1    1    1   1    1"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"V5Aaqt32iImu","executionInfo":{"status":"ok","timestamp":1601211162512,"user_tz":-540,"elapsed":2012,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"3ec37846-5e54-41d0-94fc-bfe3374f3f26","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["sentences = \"Construction was done mostly by local masons and carpenters.\\n\" \\\n","             \"He moved into the South Pavilion in 1770.\\n\" \\\n","             \"Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.\"\n","\n","corpus = {'sent0': df.T['sent'].to_dict()}\n","\n","for i, sent in enumerate(sentences.split('\\n')):\n","     corpus['sent{}'.format(i + 1)] = dict((tok, 1) for tok in sent.split())\n","# print('corpus',corpus)\n","\n","df2 = pd.DataFrame(corpus, dtype=int).fillna(0)\n","# df2\n","df2.head(10)  # show the first 10 tokens in our vocabulary for this 4-document corpus\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent0</th>\n","      <th>sent1</th>\n","      <th>sent2</th>\n","      <th>sent3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Thomas</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Jefferson</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>began</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>building</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Monticello</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>at</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>the</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>age</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>of</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>26.</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            sent0  sent1  sent2  sent3\n","Thomas        1.0    0.0    0.0    0.0\n","Jefferson     1.0    0.0    0.0    0.0\n","began         1.0    0.0    0.0    0.0\n","building      1.0    0.0    0.0    0.0\n","Monticello    1.0    0.0    0.0    1.0\n","at            1.0    0.0    0.0    0.0\n","the           1.0    0.0    1.0    0.0\n","age           1.0    0.0    0.0    0.0\n","of            1.0    0.0    0.0    0.0\n","26.           1.0    0.0    0.0    0.0"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"NLaP6s6JGv92"},"source":["# 문장의 유사도 측정\n","> 말뭉치 벡터에 대한 내적하여 계산"]},{"cell_type":"code","metadata":{"id":"UltmmhZuAznI","executionInfo":{"status":"ok","timestamp":1601211163134,"user_tz":-540,"elapsed":2626,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"670be7a9-685c-4bc7-f876-264788e3e7bf","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df2.sent0.dot(df2.sent1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"nyEzbKpUA-IR","executionInfo":{"status":"ok","timestamp":1601211163135,"user_tz":-540,"elapsed":2622,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"72ec5c55-722b-423c-e8ba-a5d0e3bd8ca8","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df2.sent0.dot(df2.sent2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"0uyE6zuPA-6w","executionInfo":{"status":"ok","timestamp":1601211163135,"user_tz":-540,"elapsed":2617,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"0e4d1041-e11e-4582-9b75-fd0b7a83cae6","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df2.sent0.dot(df2.sent3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"6ZAuisxT0cYO"},"source":["# onehot_vectors\n","\n","1. text의 단어를 나타내는 수치 벡터\n","\n","* 한성분만 빼고 모두 값이 0이다.\n","* one-hot : 값이 1인 성분 하나만  hot ( = on , positive )하다는 의미.\n","\n","\n","\n","2. one-hot vector의 sequence\n","* 원문 텍스트로 다시 변환이 가능.\n","* 수치적인 자료 구조( 2차원 수치 배열)\n","* 원문을 녹음 한 것과 비슷.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"eVHcAzE2qFlr","executionInfo":{"status":"ok","timestamp":1601211163137,"user_tz":-540,"elapsed":2615,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"c2c0771c-13a2-4539-93c8-ef0aca64d37b","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","sentence = \"Thomas Jefferson began building Monticello at the age of 26.\"\n","token_sequence = str.split(sentence)\n","vocab = sorted(set(token_sequence))\n","', '.join(vocab)\n","num_token = len(token_sequence)\n","vocab_size = len(vocab)\n","onehot_vectors = np.zeros((num_token,vocab_size), int)\n","for i, word in enumerate(token_sequence):\n","  onehot_vectors[i,vocab.index(word)] = 1\n","' '.join(vocab)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'26. Jefferson Monticello Thomas age at began building of the'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"sD0Hk2K6q8KZ","executionInfo":{"status":"ok","timestamp":1601211163139,"user_tz":-540,"elapsed":2610,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"4c5910da-71b0-4d34-cbd9-f67ced27717c","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["onehot_vectors"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n","       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n","       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n","       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n","       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"8icTz1UYq-gN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_epWgGVjsYSj","executionInfo":{"status":"ok","timestamp":1601211163141,"user_tz":-540,"elapsed":2603,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"a94c2064-907d-499d-920c-fb7dbd913b4b","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["pd.DataFrame(onehot_vectors,columns=vocab)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>26.</th>\n","      <th>Jefferson</th>\n","      <th>Monticello</th>\n","      <th>Thomas</th>\n","      <th>age</th>\n","      <th>at</th>\n","      <th>began</th>\n","      <th>building</th>\n","      <th>of</th>\n","      <th>the</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   26.  Jefferson  Monticello  Thomas  age  at  began  building  of  the\n","0    0          0           0       1    0   0      0         0   0    0\n","1    0          1           0       0    0   0      0         0   0    0\n","2    0          0           0       0    0   0      1         0   0    0\n","3    0          0           0       0    0   0      0         1   0    0\n","4    0          0           1       0    0   0      0         0   0    0\n","5    0          0           0       0    0   1      0         0   0    0\n","6    0          0           0       0    0   0      0         0   0    1\n","7    0          0           0       0    1   0      0         0   0    0\n","8    0          0           0       0    0   0      0         0   1    0\n","9    1          0           0       0    0   0      0         0   0    0"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"bUXVsy0ysv7E","executionInfo":{"status":"ok","timestamp":1601211163142,"user_tz":-540,"elapsed":2599,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"65c7d172-fc17-4d2b-cd2d-7f37e15cad23","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["df = pd.DataFrame(onehot_vectors,columns=vocab)\n","df[df==0] = ''\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>26.</th>\n","      <th>Jefferson</th>\n","      <th>Monticello</th>\n","      <th>Thomas</th>\n","      <th>age</th>\n","      <th>at</th>\n","      <th>began</th>\n","      <th>building</th>\n","      <th>of</th>\n","      <th>the</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td></td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td></td>\n","      <td></td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>1</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  26. Jefferson Monticello Thomas age at began building of the\n","0                               1                             \n","1             1                                               \n","2                                            1                \n","3                                                     1       \n","4                        1                                    \n","5                                      1                      \n","6                                                            1\n","7                                   1                         \n","8                                                        1    \n","9   1                                                         "]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"1z4e2g5ryHcR","executionInfo":{"status":"ok","timestamp":1601211163142,"user_tz":-540,"elapsed":2595,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"848710a2-a956-4048-f2c9-ce241f59d606","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["sentence_bow = {}\n","for token in sentence.split():\n","  sentence_bow[token]=1\n","sorted(sentence_bow.items())\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('26.', 1),\n"," ('Jefferson', 1),\n"," ('Monticello', 1),\n"," ('Thomas', 1),\n"," ('age', 1),\n"," ('at', 1),\n"," ('began', 1),\n"," ('building', 1),\n"," ('of', 1),\n"," ('the', 1)]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"Vz7NscA7Bv94"},"source":["# 정규 표현식을 이용한 토큰화 \n","\n","- 대괄호 \"[\" \"]\"  = 문자부류 = charactor class\n","> 주어진 텍스트가 부합해야 할 문자들의 집합\n","\n","- 대괄호 다음의 \"+\" 기호\n","> 주어진 문자부류가 하나 이상 일치 해야 함.\n","\n","- \\s \n","> 공백문자 부류를 의미\n","> r'[\\s]' = r'[ \\t\\n\\r\\f\\v]'\n","\n","- 문자 부류에서 문자 범위 지정\n","> r'[a-z]'\n","> r'[0-9]'\n","> r'[_a-zA-Z]'\n","\n","- 왼쪽대괄호 다음의 하이픈 \"-\"\n","> 하이픈 - 문자 자체를 의미   r'[\\-]'와 동일 한 의미\n","\n","- 소괄호 \"(\" \")\" = 문자열그룹\n","> r'[-\\s.,;!?]+' 는 r'([-\\s.,;!?])+' 와 동일하다."]},{"cell_type":"code","metadata":{"id":"ljWpEvjtBuh_","executionInfo":{"status":"ok","timestamp":1601211163143,"user_tz":-540,"elapsed":2590,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"4920c855-bd4e-488e-9aed-4bae1673a311","colab":{"base_uri":"https://localhost:8080/"}},"source":["import re\n","sentence = \"Thomas Jefferson began building Monticello at the age of 26.\"\n","tokens = re.split(r'[-\\s.,;!?]+',sentence)\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Thomas',\n"," 'Jefferson',\n"," 'began',\n"," 'building',\n"," 'Monticello',\n"," 'at',\n"," 'the',\n"," 'age',\n"," 'of',\n"," '26',\n"," '']"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"DSNZBJNJFG4C","executionInfo":{"status":"ok","timestamp":1601211163144,"user_tz":-540,"elapsed":2586,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"98f0a680-2e52-4388-fb12-78b7cf468e9f","colab":{"base_uri":"https://localhost:8080/"}},"source":["pattern = re.compile(r'[-\\s.,;!?]+')\n","tokens = pattern.split(sentence)\n","print (tokens)\n","[x for x in tokens if x and x not in '- \\t\\n.,;!?']\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Thomas', 'Jefferson', 'began', 'building', 'Monticello', 'at', 'the', 'age', 'of', '26', '']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['Thomas',\n"," 'Jefferson',\n"," 'began',\n"," 'building',\n"," 'Monticello',\n"," 'at',\n"," 'the',\n"," 'age',\n"," 'of',\n"," '26']"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"FNdCNoszGNGW","executionInfo":{"status":"ok","timestamp":1601211163144,"user_tz":-540,"elapsed":2581,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"c6c76c29-fc72-4095-a7b4-d37ec936f8da","colab":{"base_uri":"https://localhost:8080/"}},"source":["list(filter(lambda x: x if x and x not in '- \\t\\n.,;!?' else None , tokens))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Thomas',\n"," 'Jefferson',\n"," 'began',\n"," 'building',\n"," 'Monticello',\n"," 'at',\n"," 'the',\n"," 'age',\n"," 'of',\n"," '26']"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"lCBP928RFuQ4","executionInfo":{"status":"ok","timestamp":1601211166695,"user_tz":-540,"elapsed":6128,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"14a0b79b-6a2b-42f6-c9af-32300838b46b","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install regex"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XjBKCTDEGCFo","executionInfo":{"status":"ok","timestamp":1601211169117,"user_tz":-540,"elapsed":8544,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"03c54f34-7ba4-4d28-b574-5c64f4e359fd","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install nltk\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0ThG1grqJZ-s"},"source":["# NLTK 패키지"]},{"cell_type":"code","metadata":{"id":"QOgqhZ69IVp5","executionInfo":{"status":"ok","timestamp":1601211170206,"user_tz":-540,"elapsed":9628,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"bf53daf2-0d71-47ea-df49-921695e1f5fe","colab":{"base_uri":"https://localhost:8080/"}},"source":["from nltk.tokenize import RegexpTokenizer\n","tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\S+')\n","sentence = \"Thomas Jefferson began building Monticello at the age of 26.\"\n","tokenizer.tokenize(sentence)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Thomas',\n"," 'Jefferson',\n"," 'began',\n"," 'building',\n"," 'Monticello',\n"," 'at',\n"," 'the',\n"," 'age',\n"," 'of',\n"," '26',\n"," '.']"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"sU5CeejGIoQ5"},"source":["## NLTK 패키지의 TreebankWordTokenizer\n","1. 펜 트리뱅크 토큰화(Penn Treebank tokenization)에 기초\n","2. 영단어 에 대한 다양한 규칙을 가짐.\n","3. 소숫점 있는 수치도 처리\n","4. 축약형 단어 규칙 => 어간추출에 도움이 되는 기능\n","\n"]},{"cell_type":"code","metadata":{"id":"93hVvEfrIH_F","executionInfo":{"status":"ok","timestamp":1601211170207,"user_tz":-540,"elapsed":9623,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"45391f07-5da4-4a4f-b8dc-2a5358db0e89","colab":{"base_uri":"https://localhost:8080/"}},"source":["from nltk.tokenize import TreebankWordTokenizer\n","\n","sentence = \"The faster Harry got to the store, the faster Harry, the faster, would get home.\"\n","tokenizer = TreebankWordTokenizer()\n","token_sequence = tokenizer.tokenize(sentence.lower())\n","token_sequence"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['the',\n"," 'faster',\n"," 'harry',\n"," 'got',\n"," 'to',\n"," 'the',\n"," 'store',\n"," ',',\n"," 'the',\n"," 'faster',\n"," 'harry',\n"," ',',\n"," 'the',\n"," 'faster',\n"," ',',\n"," 'would',\n"," 'get',\n"," 'home',\n"," '.']"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"Q6k_P-oURofn"},"source":["# Casual_tokenize\n","1. sns(트윗 , 페북)에서 얻은 비형식적 text에 대한 tokenizer\n","2. 문법과 철자의 관례가 매우 다향한 텍스트 처리.\n","3. 사용자 이름을 제거하고  반복되는 문자를 줄이는데 유용."]},{"cell_type":"code","metadata":{"id":"_5NHrNRmJ7cb","executionInfo":{"status":"ok","timestamp":1601211170208,"user_tz":-540,"elapsed":9619,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"3d328492-407b-48b0-fc0b-0e50e194bab9","colab":{"base_uri":"https://localhost:8080/"}},"source":["from nltk.tokenize.casual import casual_tokenize\n","message = \"\"\"RT @TJMonticello Btest day everrrrrrrr at Monticello. Aswesommmmmmmmeeeeeee day :*)\"\"\"\n","casual_tokenize(message)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['RT',\n"," '@TJMonticello',\n"," 'Btest',\n"," 'day',\n"," 'everrrrrrrr',\n"," 'at',\n"," 'Monticello',\n"," '.',\n"," 'Aswesommmmmmmmeeeeeee',\n"," 'day',\n"," ':*)']"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"8A5KGaJoS3vi","executionInfo":{"status":"ok","timestamp":1601211170209,"user_tz":-540,"elapsed":9615,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"787cdd13-9a1f-44fb-83fd-a14bcd710864","colab":{"base_uri":"https://localhost:8080/"}},"source":["casual_tokenize(message, reduce_len=True, strip_handles=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['RT',\n"," 'Btest',\n"," 'day',\n"," 'everrr',\n"," 'at',\n"," 'Monticello',\n"," '.',\n"," 'Aswesommmeee',\n"," 'day',\n"," ':*)']"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"pcYHgQeZOZTx"},"source":["# n-gram (= n개의 문자열 ) 을 이용한 어휘 확장\n","\n","* 문장의 문자열에서 추출한 최대 n개의 문자요소로 이루어진 sequence(순열)\n","* 문자요소 = 문장을 구성 하는 문자 / 음절 / 단어 \n","\n","## n-gram의 필요성\n","1. 문장의 단어 순서에 담긴 의미를 좀더 많이 유지\n","2. NLP파이프라인을 통해 자료와 함께 그 문맥 정보를 전달 할 수 있는 수단 중의 하나 이다. ( 인접단어를 묶는다면 )\n","3. n-gram 모든 요소(토큰)을 결합하면 원본 문장을 만들 수 있다.\n","4. 희소 n-gram은 보통 생략한다. \n","> n-gram이 극히 드물게 나타난다는 것은 다른 단어와 상관관계가 없다는 의미이다.\n","5. 너무 자주 나오는 n-gram도 보통 무시한다. \n","> 말뭉치(corpus) 문서중 25%이상 등장하는 토큰이나 n-gram\n","> 불용어 , stop-word\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"EiSw1NtETHV7","executionInfo":{"status":"ok","timestamp":1601211170210,"user_tz":-540,"elapsed":9611,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"6100a5c9-6dca-4f0f-a6f4-3a921280951c","colab":{"base_uri":"https://localhost:8080/"}},"source":["from nltk.tokenize import RegexpTokenizer\n","sentence = \"Thomas Jefferson began building Monticello at the age of 26.\"\n","\n","tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\S+')\n","tokens = tokenizer.tokenize(sentence)\n","tokens = [x for x in tokens if x and x not in '- \\t\\n.,;!?']\n","tokens\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Thomas',\n"," 'Jefferson',\n"," 'began',\n"," 'building',\n"," 'Monticello',\n"," 'at',\n"," 'the',\n"," 'age',\n"," 'of',\n"," '26']"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"2kNzWJZnY2M8","executionInfo":{"status":"ok","timestamp":1601211170211,"user_tz":-540,"elapsed":9607,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"132d76e4-2bc1-48ed-abbd-bd6eb461964b","colab":{"base_uri":"https://localhost:8080/"}},"source":["from nltk.util import ngrams\n","list(ngrams(tokens,2))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Thomas', 'Jefferson'),\n"," ('Jefferson', 'began'),\n"," ('began', 'building'),\n"," ('building', 'Monticello'),\n"," ('Monticello', 'at'),\n"," ('at', 'the'),\n"," ('the', 'age'),\n"," ('age', 'of'),\n"," ('of', '26')]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"lVBwbOOUY9w6","executionInfo":{"status":"ok","timestamp":1601211170212,"user_tz":-540,"elapsed":9604,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"d91b4e68-6312-4a5c-f276-9e614510f7c2","colab":{"base_uri":"https://localhost:8080/"}},"source":["list(ngrams(tokens,3))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Thomas', 'Jefferson', 'began'),\n"," ('Jefferson', 'began', 'building'),\n"," ('began', 'building', 'Monticello'),\n"," ('building', 'Monticello', 'at'),\n"," ('Monticello', 'at', 'the'),\n"," ('at', 'the', 'age'),\n"," ('the', 'age', 'of'),\n"," ('age', 'of', '26')]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"9h4YKTK-ZduX","executionInfo":{"status":"ok","timestamp":1601211170212,"user_tz":-540,"elapsed":9595,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"8fdb1dcf-d096-4b4f-893c-6495f11241dd","colab":{"base_uri":"https://localhost:8080/"}},"source":["two_grams = list(ngrams(tokens,2))\n","[\" \".join(x) for x in two_grams]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Thomas Jefferson',\n"," 'Jefferson began',\n"," 'began building',\n"," 'building Monticello',\n"," 'Monticello at',\n"," 'at the',\n"," 'the age',\n"," 'age of',\n"," 'of 26']"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"NhrmxhHzbNuS"},"source":["# 불용어 ( stop word )\n","0. 예를 들어 수화, 쪽지로 메세지를 간략히 전달 할 때 항상 생략하는 단어들.\n","\n",">영어 = a,  the, and ,or ,of , on\n","\n",">한글 = \"자주,종종,가끔,많이\"\n","\n","2. NLP에서는 계산량을 줄이기 위해 제외하기도 한다. \n","3. 그러나 중요한 관계의 정보를 누락 할 수 있어 제외에 의한 이득이 적다.\n","> 문서 빈도 필터(3장)을 이용하면 의미없는 단어 또는 n-gram 제외가 용이하다.\n","4. 관례적으로 불용어가 유용하려면 n=4정도는 되어야 한다.\n","5. scikit-learn(318)과 NLTK(153->179)의 불용어 갯수는 서로 다른데 이는 불용어 생략에 의해 검색 엔진의 재현율이 떨어지는 문제를 얼마나 고려했냐의 문제이다.\n","\n","## 한국 불용어 \n","* https://bab2min.tistory.com/544\n","\n","* https://leo-bb.tistory.com/5\n","\n"]},{"cell_type":"code","metadata":{"id":"Qu6fuqvbaCN7","executionInfo":{"status":"ok","timestamp":1601211170782,"user_tz":-540,"elapsed":10157,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"8cb11472-9617-4fb1-ad93-633f8e420680","colab":{"base_uri":"https://localhost:8080/"}},"source":["# NLTK 불용어 목록\n","import nltk\n","nltk.download('stopwords')\n","stop_words = nltk.corpus.stopwords.words('english')\n","len(stop_words)\n","\n","# 참고자료 : 한글 stopwords \n","# https://www.ranks.nl/stopwords/korean\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["179"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"A1iZj3Z4FkUS","executionInfo":{"status":"ok","timestamp":1601211170783,"user_tz":-540,"elapsed":10150,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"6c1681ab-b4c5-4deb-98f7-70418fdc6265","colab":{"base_uri":"https://localhost:8080/"}},"source":["stop_words[:7]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i', 'me', 'my', 'myself', 'we', 'our', 'ours']"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"biWLfEEwFo_9","executionInfo":{"status":"ok","timestamp":1601211170785,"user_tz":-540,"elapsed":10144,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"4a561229-1b02-4ec5-c077-849874a262a3","colab":{"base_uri":"https://localhost:8080/"}},"source":["[sw for sw in stop_words if len(sw) == 1]\n","# 한글자 stop word는 축약형 단어를 처리 할 때 필요하다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i', 'a', 's', 't', 'd', 'm', 'o', 'y']"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"L-4HX6CwF0jF","executionInfo":{"status":"ok","timestamp":1601211170786,"user_tz":-540,"elapsed":10138,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"f26d5475-9988-4b53-9a78-fa0179a0d677","colab":{"base_uri":"https://localhost:8080/"}},"source":["from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n","len(sklearn_stop_words)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["318"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"1A_hjH_FTYyU","executionInfo":{"status":"ok","timestamp":1601211170786,"user_tz":-540,"elapsed":10129,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"288291f6-c7f7-4c24-eec6-12860ecd1069","colab":{"base_uri":"https://localhost:8080/"}},"source":["len(stop_words)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["179"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"sTmtgy-_TbrO","executionInfo":{"status":"ok","timestamp":1601211170788,"user_tz":-540,"elapsed":10124,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"4905217e-1443-49d8-ad91-ceec0ff2783b","colab":{"base_uri":"https://localhost:8080/"}},"source":["stop_words = set(stop_words) ## book error\n","u = len(stop_words.union(sklearn_stop_words))\n","u\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["378"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"pqaKU4weUyPV","executionInfo":{"status":"ok","timestamp":1601211170789,"user_tz":-540,"elapsed":10120,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"8cebb557-e8bd-4c2b-8fcd-0aba67b84528","colab":{"base_uri":"https://localhost:8080/"}},"source":["i = len(stop_words.intersection(sklearn_stop_words))\n","i"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["119"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"VyEnVj7LT6_p","executionInfo":{"status":"ok","timestamp":1601211170790,"user_tz":-540,"elapsed":10115,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"be00d4b4-265f-4208-f498-3188a7252064","colab":{"base_uri":"https://localhost:8080/"}},"source":["(u / i) *100\n","# NTLK와 scikit-learn에 모두 포함 된 stop word는 1/3밖에 안된다.\n","# 이런 차이는 왜 생겼고 어떤 차이가 만드느냐?"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["317.6470588235294"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"wH86GcOfWEuc"},"source":["# 어휘 정규화 ( normalization )\n","1. 어휘를 줄이는 다른 또다른 기법\n","> 결국 차원을 줄여 overfitting을 방지.\n","2. 비슷한 토큰을 하나로 퉁치는 기법\n","3. 대소문자 합치기( case normalization )\n","4. 어간 추출 ( stemming ) = 형태소 분석\n","5. 표제어 추출 ( lemmatization , 레머드제이션 )\n","\n","## 대소문자 합치기\n","* 대소문자를 합치는 것이 좋은가?\n","* 개체명(대명사)인식이 중요 프로젝트 과제라면 대소문자 합치기 과정은 스킵해야 함.\n","* camel case의 경우 스킵하는 규칙도 필요.\n","> FedEx\n","* 어째든 이제는 이런 과정을 생략하는 것이 이득이 크다.\n","> 정규화는 재현율을 높여주나 정밀도를 낮추기 때문이다.\n","> 현대 검색 엔진에서는 검색단어에 따옴표'를 붙혀 기능을 on/off 할 수 있다.\n","\n","## 어간 추출  stemming\n","\n","* 접미사 동사변형등을 제거하는 과정. ex) 복수형 s에 대한 처리\n","* 역시 검색 엔전의 정밀도( 반대말=false-positive 거짓양성 )를 크게 감소시킴.\n","* 대표적 어간추출기 : porter stemmer , snowball stemmer.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"VbmH3ortU6Yf","executionInfo":{"status":"ok","timestamp":1601211170791,"user_tz":-540,"elapsed":10109,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"8b18f14b-9cb0-4e6f-815e-15ea28550879","colab":{"base_uri":"https://localhost:8080/"}},"source":["def stem(phrase):\n","  return ' '.join([re.findall('^(.*ss|.*?)(s)?$',word)[0][0].strip(\"'\") for word in phrase.lower().split()])\n","stem('houses')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'house'"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"cxx4wZHVi_3q","executionInfo":{"status":"ok","timestamp":1601211170792,"user_tz":-540,"elapsed":10104,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"a04b09e1-a26c-404d-a29a-edc85461b8fe","colab":{"base_uri":"https://localhost:8080/"}},"source":["stem(\"Docter House's calls\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'docter house call'"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"gSDkYs0zjEN_","executionInfo":{"status":"ok","timestamp":1601211170793,"user_tz":-540,"elapsed":10099,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"7e95c5ea-ea10-401c-dbf3-4a142d00743d","colab":{"base_uri":"https://localhost:8080/"}},"source":["from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()\n","' '.join([stemmer.stem(w).strip(\"'\") for w in \"dish washer's washed dishes\".split()])\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'dish washer wash dish'"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"P2xONiXGlM08"},"source":["#줄리아 멘차베스 : 포터 어간추출기 파이썬 버젼.\n","#https://github.com/jedijulia/porter-stemmer/blob/master/stemmer.py\n","# 포터는 이 300줄을 짜기 위해 평생의 상당 부분을 보냄.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dn2YX1fAlmHl"},"source":["# 표제어 추출 ( lemmatization )\n","1. 단어를 그 바탕ㅇ에 담은 어근(root) 수준으로 분석하여 정규화 하는 것.\n","2. 뿌리는 같지만 다른 철자 변형도 같은 언어로 간주 하는 것.\n","3. chat, chatter, chatty , chatting을 동일하게 취급.\n","> 스푸핑(spoofing)\n","> : 이러한 단점을 이용해 엉뚱한 검색의 답을 제시하는 것.\n","\n","4. DB에 의존하여 판단한다.\n","5. 품사 태그를 단어에 부여하여 단점극복을 극복한다.\n","6. 어간 추출 앞에 표제어 추출기를 먼저 배치하여 효율을 극대화 했다.\n","> 검색의 차원을 줄이면서 재현율을 높였다.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Rx4ir7SNliiG","executionInfo":{"status":"ok","timestamp":1601211235568,"user_tz":-540,"elapsed":74860,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"c107a5e4-cc55-4c0a-c501-4d265c088776","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python -m nltk.downloader all # book error\n","import nltk\n","nltk.download('wordnet')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/omw.zip.\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Package stopwords is already up-to-date!\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet.zip.\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"qkDnwWeHqT3S","executionInfo":{"status":"ok","timestamp":1601211237608,"user_tz":-540,"elapsed":76893,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"ec1700ce-7d35-4c43-e766-87e4c6ec9355","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","lemmatizer.lemmatize(\"better\")\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'better'"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"jmw90CCvq4_t","executionInfo":{"status":"ok","timestamp":1601211237610,"user_tz":-540,"elapsed":76887,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"68dbdd97-f384-4f9b-946d-79ac87881a87","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["lemmatizer.lemmatize(\"better\", pos=\"a\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'good'"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"gkSUwyWgq_od","executionInfo":{"status":"ok","timestamp":1601211237611,"user_tz":-540,"elapsed":76881,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"954baceb-4c0c-4f91-cde6-fb21de80b364","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["lemmatizer.lemmatize(\"good\",\"a\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'good'"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"pCpBLtGMrFfi","executionInfo":{"status":"ok","timestamp":1601211237612,"user_tz":-540,"elapsed":76876,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"e90b8577-6e0e-488a-aa06-4c63eeca32f5","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["lemmatizer.lemmatize(\"goods\",pos=\"a\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'goods'"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"FSXaqcc_rPo1","executionInfo":{"status":"ok","timestamp":1601211237613,"user_tz":-540,"elapsed":76872,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"96f54cee-98aa-4222-cbd3-b8abe34c971b","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["lemmatizer.lemmatize(\"goods\",pos=\"n\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'good'"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"ynvtBs30rWKQ","executionInfo":{"status":"ok","timestamp":1601211237614,"user_tz":-540,"elapsed":76866,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"3450c354-ead4-4f0a-8471-fa1108c0dd57","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["lemmatizer.lemmatize(\"goodness\",pos=\"n\")\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'goodness'"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"XcYhOvTBrtu5","executionInfo":{"status":"ok","timestamp":1601211237614,"user_tz":-540,"elapsed":76860,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"e176405c-e2ec-4bac-a81f-ec332dd45b65","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["stemmer.stem(\"goodness\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'good'"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"1aMJwRnpr59c"},"source":["# 어간 추출기 VS 표제어 추출기\n","\n","1. 필요한 코드와 자료 잡합의 복잡도가 낮다면 일반적으로 어간 추출이 더 빠르다.\n","2. 어간 추출기는 의미의 손실이 더 크다. \n","3. 또한 단어의 중의성이 높아지게 만든다.\n","> 다 때가 있다.(때타홀 광고)\n","\n","# 검색기반 챗봇\n","1. 엄격한 검색을 먼저 수행.\n","2. 기타 정규화 적용후 검색.\n","3. 유명 검색 엔진은 이러한 400개의 독립적 알고리즘을 적용하여 검색한다.\n","\n","# 결론\n","스탠퍼드 대학교에서는 이런 어간 / 표제어 추출 교과 과정을 뺐다. 딥러닝 기술 앞에는 아무 쓸모 없기 때문이다."]},{"cell_type":"markdown","metadata":{"id":"xKfRxCOx8Q8r"},"source":["# 감정 분석 ( sentiment analysis )\n"," NLP파이프라인은 텍스트의 긍정 / 부정 / 기타감정을 수치로 표현 할 수 있다.\n"," 또한 뭔가 좋은 말을 할 수 없다면 아예 말을 하지 않을 수도 있다.\n","\n"," ## 감정 분석 방법 2가지\n"," * 사람이 규칙을 만들어 낸다.\n"," * 컴퓨터가 기존 자료를 분석하여 스스로 학습하게 만든다.\n"]},{"cell_type":"markdown","metadata":{"id":"dFcW7vgO9Ry2"},"source":["# VADER \n","* 사람이 직접 작성한 규칙 기반 감정 분서기.\n","* 정의된 토큰 : 7500개\n","* 빈칸이 포함된 토큰은 3개 ( n-gram )"]},{"cell_type":"code","metadata":{"id":"0TWcJflA9mH6","executionInfo":{"status":"ok","timestamp":1601211241300,"user_tz":-540,"elapsed":80539,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"e45d0b7b-489b-4600-ade8-8230166ff8d5","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["!pip install vaderSentiment"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting vaderSentiment\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n","\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.6.20)\n","Installing collected packages: vaderSentiment\n","Successfully installed vaderSentiment-3.3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5EyKwVlYD-w5","executionInfo":{"status":"error","timestamp":1601211436177,"user_tz":-540,"elapsed":661,"user":{"displayName":"t-kay y","photoUrl":"","userId":"00127777390101724619"}},"outputId":"15617b21-7395-477d-b0f7-4c5892076876","colab":{"base_uri":"https://localhost:8080/","height":370}},"source":["from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","sa = SentimentIntensityAnalyzer()\n","sa.lexicon\n","# VADER의 정의된 토큰은 7500개"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-54d2d3a25c49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvaderSentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaderSentiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# VADER의 정의된 토큰은 7500개\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vaderSentiment'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"3qyhXYzpEdJ-","executionInfo":{"status":"ok","timestamp":1601211241301,"user_tz":-540,"elapsed":80530,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"0a0c94d6-07c2-485e-d218-012fc0639ad2","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["[ (tok, score) for tok, score in sa.lexicon.items() if \" \" in tok]\n","# VADER에서  빈칸이 포함된 토큰은 3개 ( n-gram )"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(\"( '}{' )\", 1.6),\n"," (\"can't stand\", -2.0),\n"," ('fed up', -1.8),\n"," ('screwed up', -1.5)]"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"markdown","metadata":{"id":"iKERCp3wI9wS"},"source":["# VADER 감정 점수\n","감정의 세기(intensity) = compound ( -1 ~ 1)\n","* pos :긍정 \n","* neg :부정\n","* neu :중립"]},{"cell_type":"code","metadata":{"id":"yLBjSuPVEzp8","executionInfo":{"status":"ok","timestamp":1601211241302,"user_tz":-540,"elapsed":80526,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"e8886106-f460-45d0-dcfc-a0a99bbcac09","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sa.polarity_scores(text=\"Python is very readable and it's great for NLP.\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'compound': 0.6249, 'neg': 0.0, 'neu': 0.661, 'pos': 0.339}"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"LPRbmb5PJXl9"},"source":["## VADER는 not과 같은 부정어에 대해 상당히 잘 처리한다."]},{"cell_type":"code","metadata":{"id":"N9wsrw8zE60b","executionInfo":{"status":"ok","timestamp":1601211241303,"user_tz":-540,"elapsed":80522,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"276cefbe-a7de-42ef-b4d8-35c3d891f510","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sa.polarity_scores(text=\"Python is not a bad choice for most applications.\")\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'compound': 0.431, 'neg': 0.0, 'neu': 0.737, 'pos': 0.263}"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"v5J61tEnFg9f","executionInfo":{"status":"ok","timestamp":1601211241304,"user_tz":-540,"elapsed":80518,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"48092f7d-b168-43d1-ae4a-b4a51318eb3a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sa.polarity_scores(text=\"You're such a bad-mouth!\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0}"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"HLxNYZ1JFvfo","executionInfo":{"status":"ok","timestamp":1601211241305,"user_tz":-540,"elapsed":80513,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"f23bfe71-7a0b-4481-fde3-07e1acec3f94","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sa.polarity_scores(text=\"There're some people who like to run somebody down to draw interest.\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'compound': 0.6705, 'neg': 0.0, 'neu': 0.645, 'pos': 0.355}"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"nPAz8O89GAxI","executionInfo":{"status":"ok","timestamp":1601211241306,"user_tz":-540,"elapsed":80508,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"ff1394eb-d127-4842-80ef-632a81fbeab8","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sa.polarity_scores(text=\"The witch uttered maledictions against her captors\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'compound': -0.3612, 'neg': 0.294, 'neu': 0.706, 'pos': 0.0}"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"HvzTVX9RGOAi","executionInfo":{"status":"ok","timestamp":1601211241306,"user_tz":-540,"elapsed":80502,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"a44ccc47-d005-464f-e193-15dcc6ca37aa","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sa.polarity_scores(text=\"The witch uttered maledictions against her captors ^_^ \")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'compound': -0.3612, 'neg': 0.263, 'neu': 0.737, 'pos': 0.0}"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"h1h8VPLQGqWM","executionInfo":{"status":"ok","timestamp":1601211241307,"user_tz":-540,"elapsed":80497,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"89beb01c-eb09-43a8-811e-41fd60d76e2c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sa.polarity_scores(text=\"The witch uttered maledictions against her captors :(\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'compound': -0.6597, 'neg': 0.474, 'neu': 0.526, 'pos': 0.0}"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"WbSPSnxAH53n","executionInfo":{"status":"ok","timestamp":1601211241308,"user_tz":-540,"elapsed":80491,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"a862ebff-9a7f-4707-c048-380284a51977","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["corpus = [\"Absolutely perfect! Love it! :-) :-) :-)\",\n"," \"Horrible! Completely useless. :(\",\n"," \"It was OK. Some good and some bad things.\"]\n","for doc in corpus:\n","  scores = sa.polarity_scores(doc)\n","  print('{:+}: {}'.format(scores['compound'], doc))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+0.9428: Absolutely perfect! Love it! :-) :-) :-)\n","-0.8768: Horrible! Completely useless. :(\n","-0.1531: It was OK. Some good and some bad things.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TQh0XltBJv6r"},"source":["# 단순 베이즈 모형\n",">  문서집합(입력)에서 목표변수(출력변수)를 예측하는 키워드(입력)를 찾기 위함 이다."]},{"cell_type":"code","metadata":{"id":"-j7uBidhLXq-","executionInfo":{"status":"ok","timestamp":1601211254740,"user_tz":-540,"elapsed":93917,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"24bd16f6-5c80-408d-d439-5c5ea1a5ad7f","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install nlpia"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting nlpia\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/f6/ab35e962dd0b19f1008e88e788b202d45a90d9cd70b9bbf0ac26489ee260/nlpia-0.5.2-py2.py3-none-any.whl (32.0MB)\n","\u001b[K     |████████████████████████████████| 32.0MB 91kB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nlpia) (4.41.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from nlpia) (3.2.5)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from nlpia) (2.2.4)\n","Collecting pypandoc\n","  Downloading https://files.pythonhosted.org/packages/d6/b7/5050dc1769c8a93d3ec7c4bd55be161991c94b8b235f88bf7c764449e708/pypandoc-1.5.tar.gz\n","Collecting pugnlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/20/a9f0b1f45c074c63da716fc1b301916cc3b64c11d5cbf7cb305eafaf158a/pugnlp-0.2.6-py2.py3-none-any.whl (706kB)\n","\u001b[K     |████████████████████████████████| 716kB 41.5MB/s \n","\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from nlpia) (4.2.6)\n","Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from nlpia) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from nlpia) (2.10.0)\n","Collecting python-Levenshtein\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nlpia) (1.0.5)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from nlpia) (4.4.1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from nlpia) (2.3.0)\n","Collecting html2text\n","  Downloading https://files.pythonhosted.org/packages/ae/88/14655f727f66b3e3199f4467bafcc88283e6c31b562686bf606264e09181/html2text-2020.1.16-py3-none-any.whl\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.22.2.post1)\n","Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.8.1)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from nlpia) (1.0.0)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from nlpia) (3.6.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.16.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from nlpia) (2.4.3)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.10.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from nlpia) (3.2.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nlpia) (2019.12.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->nlpia) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (50.3.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (7.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (3.0.2)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (1.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (1.0.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (0.8.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (0.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (1.18.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (2.0.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (1.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (2.23.0)\n","Requirement already satisfied: pip>=8.1.0 in /usr/local/lib/python3.6/dist-packages (from pypandoc->nlpia) (19.3.1)\n","Requirement already satisfied: wheel>=0.25.0 in /usr/local/lib/python3.6/dist-packages (from pypandoc->nlpia) (0.35.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from pugnlp->nlpia) (4.0.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pugnlp->nlpia) (1.4.1)\n","Collecting fuzzywuzzy\n","  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n","Requirement already satisfied: coverage in /usr/local/lib/python3.6/dist-packages (from pugnlp->nlpia) (3.7.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->nlpia) (0.5.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlpia) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->nlpia) (2.8.1)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->nlpia) (1.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (3.3.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (0.3.3)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (0.2.0)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (2.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (3.12.4)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (2.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.12.1)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.1.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.32.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.6.3)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (0.10.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nlpia) (0.16.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (5.6.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (4.10.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (7.5.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (5.2.0)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (4.7.7)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (5.3.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->nlpia) (2.1.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->nlpia) (3.13)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nlpia) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nlpia) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nlpia) (2.4.7)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->nlpia) (1.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->nlpia) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->nlpia) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->nlpia) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->nlpia) (1.24.3)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->pugnlp->nlpia) (1.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (3.2.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (0.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (1.7.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (1.17.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (4.6.3)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (1.4.2)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (3.2.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (0.4.4)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (2.11.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (4.3.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (0.6.0)\n","Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (5.0.7)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->nlpia) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->nlpia) (5.1.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->nlpia) (5.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->nlpia) (3.5.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->nlpia) (1.0.18)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (0.2.0)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (19.0.2)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (1.9.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nlpia) (0.8.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nlpia) (1.5.0)\n","Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->nlpia) (2.49.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->nlpia) (1.14.63)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->nlpia) (3.1.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->nlpia) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->nlpia) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->nlpia) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->nlpia) (4.1.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->nlpia) (20.4)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter->nlpia) (1.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert->jupyter->nlpia) (4.4.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter->nlpia) (2.6.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.8.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.7.5)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->nlpia) (0.2.5)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->nlpia) (0.6.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->nlpia) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->nlpia) (0.10.0)\n","Requirement already satisfied: botocore<1.18.0,>=1.17.63 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->nlpia) (1.17.63)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->nlpia) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->nlpia) (0.4.8)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.63->boto3->smart-open>=1.2.1->gensim->nlpia) (0.15.2)\n","Building wheels for collected packages: pypandoc, python-Levenshtein\n","  Building wheel for pypandoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypandoc: filename=pypandoc-1.5-cp36-none-any.whl size=17038 sha256=16fc459504b824679c3ff0674e1ad0e43ecc5dfcc74113fc594326bced7cde2d\n","  Stored in directory: /root/.cache/pip/wheels/bb/7d/d6/2f9af55e800d37e42e546106bcbd36a86e24e725e303d17e04\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144794 sha256=7ecfdaeba2830ecb106caef57ec9118642e9544540184c468d26d1d5e52bb880\n","  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n","Successfully built pypandoc python-Levenshtein\n","Installing collected packages: pypandoc, fuzzywuzzy, python-Levenshtein, pugnlp, html2text, nlpia\n","Successfully installed fuzzywuzzy-0.18.0 html2text-2020.1.16 nlpia-0.5.2 pugnlp-0.2.6 pypandoc-1.5 python-Levenshtein-0.12.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GiyyEhocJsci","executionInfo":{"status":"ok","timestamp":1601211259151,"user_tz":-540,"elapsed":98322,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"386866fc-a884-4a47-dea5-f3d1b430549a","colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["from nlpia.data.loaders import get_data  # noqa\n","movies = get_data('hutto_movies')\n","movies.head().round(2)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pugnlp/constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n","  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n","/usr/local/lib/python3.6/dist-packages/nlpia/futil.py:370: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n","  if (series == np.arange(len(series))).all():\n","/usr/local/lib/python3.6/dist-packages/nlpia/futil.py:373: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n","  (series.index == np.arange(len(series))).all() and\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2.27</td>\n","      <td>The Rock is destined to be the 21st Century's ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.53</td>\n","      <td>The gorgeously elaborate continuation of ''The...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.60</td>\n","      <td>Effective but too tepid biopic</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.47</td>\n","      <td>If you sometimes like to go to the movies to h...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.73</td>\n","      <td>Emerges as something rare, an issue movie that...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sentiment                                               text\n","id                                                              \n","1        2.27  The Rock is destined to be the 21st Century's ...\n","2        3.53  The gorgeously elaborate continuation of ''The...\n","3       -0.60                     Effective but too tepid biopic\n","4        1.47  If you sometimes like to go to the movies to h...\n","5        1.73  Emerges as something rare, an issue movie that..."]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"c60gjrDZScNZ","executionInfo":{"status":"ok","timestamp":1601211259153,"user_tz":-540,"elapsed":98319,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"e64325c2-1219-4f71-e950-0c13598cf983","colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["movies.describe().round(2)\n","# 자료수 10605개\n","# 평가 수치 min~max : -3.88 ~ 3.94"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>10605.00</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.92</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-3.88</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-1.77</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-0.08</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.83</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.94</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       sentiment\n","count   10605.00\n","mean        0.00\n","std         1.92\n","min        -3.88\n","25%        -1.77\n","50%        -0.08\n","75%         1.83\n","max         3.94"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"pyUYw3ndTJjg","executionInfo":{"status":"ok","timestamp":1601211302940,"user_tz":-540,"elapsed":142100,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"6c287809-274b-4bbe-f777-8972f3d219c7","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import pandas as pd  # noqa\n","pd.set_option('display.width', 75) # 출력 데이타를 보기좋게 조정\n","from nltk.tokenize import casual_tokenize  # 비속어에 대한 처리를 잘 한다.\n","from collections import Counter  # noqa\n","print('movies.text length =', len(movies.text))\n","bags_of_words = []\n","for text in movies.text:\n","    bags_of_words.append(Counter(casual_tokenize(text)))\n","\n","df_bows = pd.DataFrame.from_records(bags_of_words)\n","df_bows = df_bows.fillna(0).astype(int) # NA를 int형 0으로 바꾸어 메모리 절약.\n","df_bows.shape\n","# 데이타수 : 10605 , 토큰수 : 20765\n","# 대소문자 정규화 / 불용어처리 / 어간추출 / 표제어 추출을 하지 않았다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["movies.text length = 10605\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(10605, 20756)"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"bakFRjQJVGBf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eg9T590ZVHB3"},"source":["### 코드 설명\n","\n","* print(text)\n","```\n","The Rock is destined to be the 21st Century's new ''Conan'' and that he's going to make a splash even greater than Arnold Schwarzenegger, Jean Claud Van Damme or Steven Segal.\n","```\n","\n","*     print(casual_tokenize(text))\n","```\n","['The', 'Rock', 'is', 'destined', 'to', 'be', 'the', '21st', \"Century's\", 'new', \"'\", \"'\", 'Conan', \"'\", \"'\", 'and', 'that', \"he's\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'Arnold', 'Schwarzenegger', ',', 'Jean', 'Claud', 'Van', 'Damme', 'or', 'Steven', 'Segal', '.']\n","```\n","\n","*     print(Counter(casual_tokenize(text)))\n","```json\n","Counter({\"'\": 4, 'to': 2, 'The': 1, 'Rock': 1, 'is': 1, 'destined': 1, 'be': 1, 'the': 1, '21st': 1, \"Century's\": 1, 'new': 1, 'Conan': 1, 'and': 1, 'that': 1, \"he's\": 1, 'going': 1, 'make': 1, 'a': 1, 'splash': 1, 'even': 1, 'greater': 1, 'than': 1, 'Arnold': 1, 'Schwarzenegger': 1, ',': 1, 'Jean': 1, 'Claud': 1, 'Van': 1, 'Damme': 1, 'or': 1, 'Steven': 1, 'Segal': 1, '.': 1})\n","\n","```\n"]},{"cell_type":"code","metadata":{"id":"oUCqhkrkUc2U","executionInfo":{"status":"ok","timestamp":1601211302942,"user_tz":-540,"elapsed":142091,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"ea7a5307-554c-4edb-fb0b-d09c764d1b2d","colab":{"base_uri":"https://localhost:8080/","height":253}},"source":["df_bows.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>The</th>\n","      <th>Rock</th>\n","      <th>is</th>\n","      <th>destined</th>\n","      <th>to</th>\n","      <th>be</th>\n","      <th>the</th>\n","      <th>21st</th>\n","      <th>Century's</th>\n","      <th>new</th>\n","      <th>'</th>\n","      <th>Conan</th>\n","      <th>and</th>\n","      <th>that</th>\n","      <th>he's</th>\n","      <th>going</th>\n","      <th>make</th>\n","      <th>a</th>\n","      <th>splash</th>\n","      <th>even</th>\n","      <th>greater</th>\n","      <th>than</th>\n","      <th>Arnold</th>\n","      <th>Schwarzenegger</th>\n","      <th>,</th>\n","      <th>Jean</th>\n","      <th>Claud</th>\n","      <th>Van</th>\n","      <th>Damme</th>\n","      <th>or</th>\n","      <th>Steven</th>\n","      <th>Segal</th>\n","      <th>.</th>\n","      <th>gorgeously</th>\n","      <th>elaborate</th>\n","      <th>continuation</th>\n","      <th>of</th>\n","      <th>Lord</th>\n","      <th>Rings</th>\n","      <th>trilogy</th>\n","      <th>...</th>\n","      <th>Overwrought</th>\n","      <th>snooze</th>\n","      <th>Feeble</th>\n","      <th>salaciously</th>\n","      <th>Disjointed</th>\n","      <th>humbuggery</th>\n","      <th>Eh</th>\n","      <th>unrealistic</th>\n","      <th>nrelentingly</th>\n","      <th>Painfully</th>\n","      <th>Grating</th>\n","      <th>Dramatically</th>\n","      <th>Predictably</th>\n","      <th>Arty</th>\n","      <th>Incoherence</th>\n","      <th>reigns</th>\n","      <th>assed</th>\n","      <th>Abysmally</th>\n","      <th>Bland</th>\n","      <th>ame</th>\n","      <th>drudgery</th>\n","      <th>snubbing</th>\n","      <th>Mildly</th>\n","      <th>Terrible</th>\n","      <th>Degenerates</th>\n","      <th>hogwash</th>\n","      <th>Crummy</th>\n","      <th>Wishy</th>\n","      <th>Inconsequential</th>\n","      <th>Insufferably</th>\n","      <th>Ill</th>\n","      <th>slummer</th>\n","      <th>Rashomon</th>\n","      <th>dipsticks</th>\n","      <th>Bearable</th>\n","      <th>Staggeringly</th>\n","      <th>’</th>\n","      <th>ve</th>\n","      <th>muttering</th>\n","      <th>dissing</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 20756 columns</p>\n","</div>"],"text/plain":["   The  Rock  is  destined  to  ...  Staggeringly  ’  ve  muttering  dissing\n","0    1     1   1         1   2  ...             0  0   0          0        0\n","1    2     0   1         0   0  ...             0  0   0          0        0\n","2    0     0   0         0   0  ...             0  0   0          0        0\n","3    0     0   1         0   4  ...             0  0   0          0        0\n","4    0     0   0         0   0  ...             0  0   0          0        0\n","\n","[5 rows x 20756 columns]"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"ocHFzt78WGVh","executionInfo":{"status":"ok","timestamp":1601211302942,"user_tz":-540,"elapsed":142085,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"188520e0-200f-40e0-a9a4-b7142ed918e1","colab":{"base_uri":"https://localhost:8080/","height":578}},"source":["list(bags_of_words[0].keys())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The',\n"," 'Rock',\n"," 'is',\n"," 'destined',\n"," 'to',\n"," 'be',\n"," 'the',\n"," '21st',\n"," \"Century's\",\n"," 'new',\n"," \"'\",\n"," 'Conan',\n"," 'and',\n"," 'that',\n"," \"he's\",\n"," 'going',\n"," 'make',\n"," 'a',\n"," 'splash',\n"," 'even',\n"," 'greater',\n"," 'than',\n"," 'Arnold',\n"," 'Schwarzenegger',\n"," ',',\n"," 'Jean',\n"," 'Claud',\n"," 'Van',\n"," 'Damme',\n"," 'or',\n"," 'Steven',\n"," 'Segal',\n"," '.']"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"ds_tc2FyUhkd","executionInfo":{"status":"ok","timestamp":1601211302943,"user_tz":-540,"elapsed":142080,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"273e50ac-acbf-41f9-b73e-c9d711b3f7bd","colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["show_fields_list = list(bags_of_words[0].keys())\n","df_bows.head()[show_fields_list]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>The</th>\n","      <th>Rock</th>\n","      <th>is</th>\n","      <th>destined</th>\n","      <th>to</th>\n","      <th>be</th>\n","      <th>the</th>\n","      <th>21st</th>\n","      <th>Century's</th>\n","      <th>new</th>\n","      <th>'</th>\n","      <th>Conan</th>\n","      <th>and</th>\n","      <th>that</th>\n","      <th>he's</th>\n","      <th>going</th>\n","      <th>make</th>\n","      <th>a</th>\n","      <th>splash</th>\n","      <th>even</th>\n","      <th>greater</th>\n","      <th>than</th>\n","      <th>Arnold</th>\n","      <th>Schwarzenegger</th>\n","      <th>,</th>\n","      <th>Jean</th>\n","      <th>Claud</th>\n","      <th>Van</th>\n","      <th>Damme</th>\n","      <th>or</th>\n","      <th>Steven</th>\n","      <th>Segal</th>\n","      <th>.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   The  Rock  is  destined  to  be  ...  Van  Damme  or  Steven  Segal  .\n","0    1     1   1         1   2   1  ...    1      1   1       1      1  1\n","1    2     0   1         0   0   0  ...    0      0   0       0      0  4\n","2    0     0   0         0   0   0  ...    0      0   0       0      0  0\n","3    0     0   1         0   4   0  ...    0      0   0       0      0  1\n","4    0     0   0         0   0   0  ...    0      0   0       0      0  1\n","\n","[5 rows x 33 columns]"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"6AAoY4T5V6__"},"source":["from sklearn.naive_bayes import MultinomialNB  # 사이킷런 다항분포 나이브베이즈\n","nb = MultinomialNB()\n","\n","# 나이브베이즈는 분류기(classifier)이므로 부동소숫점을 이산자료형(정수,문자,bool)으로 변환.\n","nb = nb.fit(df_bows, movies.sentiment > 0) \n","# movies.sentiment > 0\n","#   => 평가 수치 min~max : -3.88 ~ 3.94 에 대해 긍정/부정으로 목표값 세팅\n","# type(df_bows) = 'pandas.core.frame.DataFrame'\n","# type(movies.sentiment) = 'pandas.core.series.Series'\n","\n","movies['predicted_sentiment'] = nb.predict(df_bows) * 8 - 4 \n","# 나이브베이즈 모델로 예측을 해본다. \n","#값을 -4~4로 보정했다.\n","\n","movies['error'] = (movies.predicted_sentiment - movies.sentiment).abs()\n","# 정답과 예측값을 비교하여 에러인지 표시.\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HxRS900NkNh3"},"source":["* 평균절대오차 ( mean absolute error = MAE)\n",">  예측값과 정답에 대한 오차의 절대값들의 평균\n",">\n",">  만약 무작위로 선택후 긍정/부정을 아무렇게나 판단 했을때의 MAE = 4 이다."]},{"cell_type":"code","metadata":{"id":"yVOdOccsYyP7","executionInfo":{"status":"ok","timestamp":1601211307157,"user_tz":-540,"elapsed":146281,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"96c7917b-282e-46bf-e199-7c55a1dea6af","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["round(movies.error.mean(),2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.39"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"RP8ljH8wYusN","executionInfo":{"status":"ok","timestamp":1601211307157,"user_tz":-540,"elapsed":146276,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"87ab1f47-c02e-413f-b3e3-030be52eef2c","colab":{"base_uri":"https://localhost:8080/","height":638}},"source":["# 2.4\n","movies['sentiment_ispositive'] = (movies.sentiment > 0).astype(int)\n","movies['predicted_ispos'] = (movies.predicted_sentiment > 0).astype(int)\n","movies['sentiment predicted_sentiment sentiment_ispositive predicted_ispos'\n","       .split()].head(18)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>predicted_sentiment</th>\n","      <th>sentiment_ispositive</th>\n","      <th>predicted_ispos</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2.266667</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.533333</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.600000</td>\n","      <td>-4</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.466667</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.733333</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2.533333</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2.466667</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.266667</td>\n","      <td>-4</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1.933333</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1.733333</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2.066667</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1.666667</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>3.133333</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>3.666667</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1.333333</td>\n","      <td>-4</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>2.200000</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1.000000</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>3.400000</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sentiment  predicted_sentiment  sentiment_ispositive  predicted_ispos\n","id                                                                       \n","1    2.266667                    4                     1                1\n","2    3.533333                    4                     1                1\n","3   -0.600000                   -4                     0                0\n","4    1.466667                    4                     1                1\n","5    1.733333                    4                     1                1\n","6    2.533333                    4                     1                1\n","7    2.466667                    4                     1                1\n","8    1.266667                   -4                     1                0\n","9    1.933333                    4                     1                1\n","10   1.733333                    4                     1                1\n","11   2.066667                    4                     1                1\n","12   1.666667                    4                     1                1\n","13   3.133333                    4                     1                1\n","14   3.666667                    4                     1                1\n","15   1.333333                   -4                     1                0\n","16   2.200000                    4                     1                1\n","17   1.000000                    4                     1                1\n","18   3.400000                    4                     1                1"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"RzTxa7sJk81y","executionInfo":{"status":"ok","timestamp":1601211307158,"user_tz":-540,"elapsed":146271,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"5bbb2f36-731b-44a6-87f8-6b460fc76e9a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["(movies.predicted_ispos == movies.sentiment_ispositive).sum() / len(movies) # book spell error\n","# 만약 영화에 대해 긍정적 추천 평가가 93%이상이면 정확 하다고 볼 수 있다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9344648750589345"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"pJR7PlVXlb1P"},"source":["# 영화평 감정평가 모델을 이용해 상품평 감정평가 하기."]},{"cell_type":"code","metadata":{"id":"fI10WINHizKK","executionInfo":{"status":"ok","timestamp":1601211307158,"user_tz":-540,"elapsed":146265,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"93f21af0-a802-436c-e14d-648f35669646","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["products = get_data('hutto_products')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nlpia/futil.py:370: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n","  if (series == np.arange(len(series))).all():\n","/usr/local/lib/python3.6/dist-packages/nlpia/futil.py:373: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n","  (series.index == np.arange(len(series))).all() and\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"bkVjjemlmZQN","executionInfo":{"status":"ok","timestamp":1601211313715,"user_tz":-540,"elapsed":152816,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"f5d9a094-1c0e-452f-9bf7-8e9cdb4648f8","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["bags_of_words = []\n","for text in products.text:\n","    bags_of_words.append(Counter(casual_tokenize(text)))\n","df_product_bows = pd.DataFrame.from_records(bags_of_words)\n","df_product_bows = df_product_bows.fillna(0).astype(int)\n","df_all_bows = df_bows.append(df_product_bows)\n","# 영화평에 상품평 토큰 필드를 모두 합친다.\n","\n","df_all_bows.columns.values\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['The', 'Rock', 'is', ..., 'voids', 'baghdad', 'harddisk'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"C8NZWTtZmjED","executionInfo":{"status":"ok","timestamp":1601211313716,"user_tz":-540,"elapsed":152811,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"388038cc-a156-4290-d866-81a911fc9a3c","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["df_all_bows.columns\n","# 영화평 + 상품평의 단어수 : 23302"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['The', 'Rock', 'is', 'destined', 'to', 'be', 'the', '21st',\n","       'Century's', 'new',\n","       ...\n","       'sligtly', 'owner', '81', 'defectively', 'warrranty', 'expire',\n","       'expired', 'voids', 'baghdad', 'harddisk'],\n","      dtype='object', length=23302)"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"AkSmyEuooivq","executionInfo":{"status":"ok","timestamp":1601211314158,"user_tz":-540,"elapsed":153247,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"67d4c55d-330d-4791-bada-b83a0a1013eb","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df_product_bows = df_all_bows.iloc[len(movies):][df_bows.columns]\n","df_product_bows.shape\n","# 영화평의 단어와 중복되는 상품평의 단어수 : 20756\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3546, 20756)"]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"code","metadata":{"id":"a9IHtaE8okA-","executionInfo":{"status":"ok","timestamp":1601211314737,"user_tz":-540,"elapsed":153821,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"c41371d2-ece4-405c-8c06-1216c352c20d","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df_product_bows = df_product_bows.fillna(0).astype(int)\n","df_bows.shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10605, 20756)"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"5FZR4dlYomGU","executionInfo":{"status":"ok","timestamp":1601211316420,"user_tz":-540,"elapsed":155499,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"9bc4d181-1c34-4cb6-8ad6-fafcc60ac83f","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["\n","products['ispos'] = (products.sentiment > 0).astype(int) # 정답 ( 목표값 )\n","products['pred'] = nb.predict(df_product_bows.values).astype(int) # 나이브베이즈 예측값 \n","df_product_bows.values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"7Sop2RyDopWO","executionInfo":{"status":"ok","timestamp":1601211316421,"user_tz":-540,"elapsed":155494,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"ed5d7dfc-2810-4438-94ca-9e53877e2ddc","colab":{"base_uri":"https://localhost:8080/","height":669}},"source":["products.head(20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","      <th>ispos</th>\n","      <th>pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1_1</td>\n","      <td>-0.90</td>\n","      <td>troubleshooting ad-2500 and ad-2600 no picture...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1_2</td>\n","      <td>-0.15</td>\n","      <td>repost from january 13, 2004 with a better fit...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1_3</td>\n","      <td>-0.20</td>\n","      <td>does your apex dvd player only play dvd audio ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1_4</td>\n","      <td>-0.10</td>\n","      <td>or does it play audio and video but scrolling ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1_5</td>\n","      <td>-0.50</td>\n","      <td>before you try to return the player or waste h...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1_6</td>\n","      <td>-0.95</td>\n","      <td>no picture:  hopefully you still have the remo...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1_7</td>\n","      <td>-0.10</td>\n","      <td>if you tossed it out the window, you need to f...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1_8</td>\n","      <td>0.10</td>\n","      <td>using the remote control, press the i/p button...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1_9</td>\n","      <td>0.20</td>\n","      <td>the i/p button switches the tv display between...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1_10</td>\n","      <td>-0.05</td>\n","      <td>if this doesnt bring back the picture, try pre...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1_11</td>\n","      <td>-1.15</td>\n","      <td>if you dont get video back, now you can run th...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1_12</td>\n","      <td>-0.65</td>\n","      <td>picture scrolling in b/w:  you need the remote...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1_13</td>\n","      <td>0.05</td>\n","      <td>press the p/n button located on the bottom rig...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1_14</td>\n","      <td>0.25</td>\n","      <td>the p/n button switches your dvd players video...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1_15</td>\n","      <td>1.15</td>\n","      <td>by pressing p/n, you should be able to get a g...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1_16</td>\n","      <td>0.20</td>\n","      <td>for other problems go to http://www.apexdigita...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>1_17</td>\n","      <td>-0.70</td>\n","      <td>i have done some research and experimenting wi...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1_18</td>\n","      <td>1.75</td>\n","      <td>im a more happier person after discovering the...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1_19</td>\n","      <td>-0.65</td>\n","      <td>the button was probably accidentally pushed to...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1_20</td>\n","      <td>2.85</td>\n","      <td>but, if you're looking for my opinion of the a...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  sentiment  ... ispos  pred\n","0    1_1      -0.90  ...     0     0\n","1    1_2      -0.15  ...     0     0\n","2    1_3      -0.20  ...     0     0\n","3    1_4      -0.10  ...     0     0\n","4    1_5      -0.50  ...     0     0\n","5    1_6      -0.95  ...     0     1\n","6    1_7      -0.10  ...     0     0\n","7    1_8       0.10  ...     1     0\n","8    1_9       0.20  ...     1     0\n","9   1_10      -0.05  ...     0     0\n","10  1_11      -1.15  ...     0     0\n","11  1_12      -0.65  ...     0     0\n","12  1_13       0.05  ...     1     0\n","13  1_14       0.25  ...     1     0\n","14  1_15       1.15  ...     1     0\n","15  1_16       0.20  ...     1     0\n","16  1_17      -0.70  ...     0     0\n","17  1_18       1.75  ...     1     0\n","18  1_19      -0.65  ...     0     0\n","19  1_20       2.85  ...     1     0\n","\n","[20 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"-SF0aoKyos5W","executionInfo":{"status":"ok","timestamp":1601211316421,"user_tz":-540,"elapsed":155486,"user":{"displayName":"Ryan cho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3AZTIhyfvJ2ayrXxil2E0kIVSa_RE_HW1A3_NsJQ=s64","userId":"08226458874097834926"}},"outputId":"a143c9de-8d13-43aa-831e-29117cd7a6f6","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["(products.pred == products.ispos).sum() / len(products)\n","#  영화평에 대한 나이브베이즈 예측 확률은 0.9344648750589345 이였다."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5572476029328821"]},"metadata":{"tags":[]},"execution_count":81}]}]}